from prepare_data import Data
from neural_network import OurNeuralNetwork
import time
import numpy as np
import matplotlib.pyplot as plt

"""start_time0 = time.time()

inputdata = Data('data_w_source.txt', "class_labels.txt")
data = inputdata.get_data()
answers = inputdata.get_answers()

print("Завершена распаковка данных, начинается обработка")

for i in range(len(data)):
    for j in range(len(data[i])):
        tmp = max(data[i])
        if data[i][j] == tmp:
            data[i] = data[i][j - 50:j + 450]
            break

data2 = data[:30]
answers2 = answers[:30]

print("Завершена обработка данных, запуск нейронной сети")
start_time = time.time()
# создание нейронки
network = OurNeuralNetwork(3, 500, 25, 1)


def training():
    network.train(data2, answers2)
    with open("weights.txt", "w") as f:
        for i in network.weights:
            for j in i:
                f.write(" ".join(map(str, j)) + "\n")
            f.write("__\n")

    with open("biases.txt", "w") as f:
        for i in network.layers:
            s = []
            for j in i.neurons:
                s.append(j.bias)
            f.write(" ".join(map(str, s)) + "\n")
    print("Тренировка окончена")


def practic():
    prac_anss = []
    for i in range(len(data)):
        tmp = network.feedforward(data[i])
        prac_anss.append(round(tmp))

    pers = 0
    lie1 = 0
    lie0 = 0
    for i in range(len(answers)):
        if prac_anss[i] == answers[i]:
            pers += 1
        elif prac_anss[i] == 1 and answers[i] == 0:
            lie1 += 1
        elif prac_anss[i] == 0 and answers[i] == 1:
            lie0 += 1
    statistic.append(pers / len(answers) * 100)


statistic = []
for i in range(150):
    practic()
    training()"""


fig, ax = plt.subplots()

statistic = [20.169677066228793, 20.169677066228793, 20.169677066228793, 20.169677066228793, 20.169677066228793,
             20.169677066228793, 20.169677066228793, 20.169677066228793, 20.169677066228793, 20.169677066228793,
             20.169677066228793, 20.169677066228793, 20.169677066228793, 79.83032293377121, 79.83032293377121,
             79.83032293377121, 79.83032293377121, 79.83032293377121, 79.83032293377121, 79.83032293377121,
             79.83032293377121, 79.83032293377121, 79.83032293377121, 79.83032293377121, 79.83032293377121,
             79.83032293377121, 79.83032293377121, 79.83032293377121, 79.83032293377121, 79.83032293377121,
             79.83032293377121, 79.83032293377121, 79.83032293377121, 79.83032293377121, 79.83032293377121,
             79.83032293377121, 79.83032293377121, 79.83032293377121, 79.83032293377121, 79.83032293377121,
             79.83032293377121, 79.83032293377121, 79.83032293377121, 79.83032293377121, 79.83032293377121,
             79.83032293377121, 79.83032293377121, 79.83032293377121, 79.83032293377121, 79.83032293377121,
             79.83032293377121, 79.83032293377121, 79.83032293377121, 79.83032293377121, 79.83032293377121,
             79.83032293377121, 79.83032293377121, 79.83032293377121, 79.83032293377121, 79.83032293377121,
             79.83032293377121, 79.83032293377121, 79.83032293377121, 79.83032293377121, 79.83032293377121,
             79.83032293377121, 79.83032293377121, 79.83032293377121, 79.83032293377121, 79.83032293377121,
             79.83032293377121, 79.83032293377121, 79.83032293377121, 79.83032293377121, 79.83032293377121,
             83.36070060207992, 88.3415435139573, 91.81718664477285, 93.86973180076629, 95.64860426929393,
             97.04433497536947, 97.72851669403394, 98.22112753147236, 98.54953475643131, 98.85057471264368,
             98.90530925013684, 98.93267651888341, 99.01477832512316, 99.04214559386973, 99.17898193760263,
             99.20634920634922, 99.26108374384236, 99.26108374384236, 99.23371647509579, 99.28845101258894,
             99.31581828133552, 99.3431855500821, 99.3431855500821, 99.42528735632183, 99.42528735632183,
             99.48002189381499, 99.48002189381499, 99.48002189381499, 99.48002189381499, 99.48002189381499,
             99.48002189381499, 99.48002189381499, 99.48002189381499, 99.48002189381499, 99.50738916256158,
             99.50738916256158, 99.50738916256158, 99.50738916256158, 99.50738916256158, 99.53475643130815,
             99.53475643130815, 99.53475643130815, 99.53475643130815, 99.53475643130815, 99.53475643130815,
             99.56212370005474, 99.56212370005474, 99.56212370005474, 99.56212370005474, 99.56212370005474,
             99.56212370005474, 99.56212370005474, 99.56212370005474, 99.56212370005474, 99.56212370005474,
             99.56212370005474, 99.56212370005474, 99.56212370005474, 99.56212370005474, 99.56212370005474,
             99.56212370005474, 99.56212370005474, 99.56212370005474, 99.56212370005474, 99.56212370005474,
             99.56212370005474, 99.56212370005474, 99.56212370005474, 99.56212370005474, 99.56212370005474,
             99.56212370005474, 99.58949096880131, 99.58949096880131, 99.58949096880131, 99.58949096880131]
plt.xlabel("Кол-во эпох обучения нейросети")
plt.ylabel("Точность нейросети")

x1 = [i + 1 for i in range(len(statistic))]

plt.plot(np.asarray(x1), np.asarray(statistic))
ax.grid()

plt.show()
